---
title: test
date: 2021-06-02T12:31:22.153Z
description: test
draft: false
hideToc: false
enableToc: true
enableTocContent: false
author: Hristo Vuchev
authorEmoji: "#"
image: /images/opengl.png
tags:
  - test
categories:
  - test
series:
  - test
---
# **Module Introduction**

For this module we had to compare different AI techniques. Which those techniques are was up to us. During the semester we studied Finite State Machines, Rule Based Systems, Fuzzy Logic, Reinforcement and Predictive Learning, Genetic Algorithms, Case Based Reasoning, Artificial Neural Networks, Self-Organaing Maps and Clustering and Deep Neural Networks. I decided to compare 3 different techniques from Machine Learning - Reinforcement Learning and 2 types of Imitation Learning - Behavioral Cloning and GAIL (Generative Adversarial Imitation Learning)

### AI in games

Video Games have been using different Artificial Intelligence techniques since the very beginning. Although some of those techniques might not necessarily be classified as “intelligent” in 2021. Artificial Intelligence in games could be as simple as calculating where the paddle in “Pong” should be, deciding the state and the behaviour of the ghosts in “Pac-Man” or beating the very best players in one of the most complex style of games we have to date, using Artificial Neural Networks (OpenAI) - “Dota 2”.

The goals of Games AI are often very different compared to the goals of Academic AI. In games AI serves the purpose to enhance the experience of the player as well as providing better entertainment or immersion. It does not focus on being better than the player and finding a balance between how strong the AI should be is often difficult. Another limiting factor in Games AI is computational power, often the computers of the players are far from the best in class, thus the Game AI is made to use much less resources than Academic AI.

An example of common Games AI techniques are Finite State Machines (FSM). One of the earliest uses of an FSM is the game “Pac-Man”. Each Ghost in the game has the same “Evade” state, which is triggered when the player interacts with a pill. Each Ghost also has its own implementation of the “Chase” state, giving each ghost a unique character. Transitioning from Evade to Chase happens on a timer, which when expires, the state changes. FSM’s are still commonly used in modern games for Non Playable Characters (NPC’s), a simple example is a guard who has a couple of states - Patrolling, Alert, Engaging.

### Project Introduction

This application demonstrates a different AI technique, Machine Learning. More precisely how three different types of machine learning compare against each other in a semi-complex example built in Unity. The runnable application includes the trained brains showcasing the respective results of the testing. The ML library used was the ML-Agents package from Unity. The three ML algorithms used were Reinforcement Learning, GAIL (Generative Adversarial Imitation Learning) and Behavioral Cloning. The test scenario in the application is a small environment which contains a player (who has an ML agent), a button/trigger, and a goal which is created when the button is pressed. A full test loop includes the player being created at a random point in the environment, the button being created in another random point, the player agent navigating successfully to the location of the button, interacting with it in order to spawn the goal, then locating the goal and the player agent reaching the goal. The inputs for the ML agent are using the unity input system. The inputs are the player movement on the Horizontal and Vertical axis and an interaction key (“E”) to use the button and spawn the goal.

This AI technique was chosen due to the vast pot

<!--EndFragment-->